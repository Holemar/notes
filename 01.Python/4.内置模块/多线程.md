
# python虚拟机
Python代码代码的执行由python虚拟机（也叫解释器主循环）来控制。  
Python在设计之初就考虑到要在主循环中，同时只有一个线程在执行，就像单CPU的系统中运行多个进程那样，内存中可以存放多个程序，但任意时候，只有一个程序在CPU中运行。  
同样，虽然python解释器可以“运行”多个线程，但在任意时刻，只有一个线程在解释器中运行。  


# 多线程
1. 函数式：调用`thread`模块中的`start_new_thread()`函数来产生新线程。如：

```python
import time
try:
    import thread
except ImportError:
    import _thread as thread  # Python3.x 废弃了 thread 模块，使用 _thread 模块代替

def timer(no, interval):
    cnt = 0
    while cnt<10:
        print('Thread:(%d) Time:%s\n'%(no, time.ctime()))
        #time.sleep(interval)
        cnt += 1
    # 线程的结束可以等待线程自然结束，也可以在线程函数中调用 thread.exit() 或 thread.exit_thread() 方法。
    thread.exit_thread()

def test():
    # 用 thread.start_new_thread() 来创建两个线程
    # thread.start_new_thread(function, args[, kwargs]) 的第一个参数是线程函数；第二个参数是传递给线程函数的参数，它必须是tuple类型；kwargs是可选参数
    thread1 = thread.start_new_thread(timer, (1,1))
    thread2 = thread.start_new(timer, (2,2)) # start_new 是 start_new_thread 的另一个名称, 不过这名称已过时
    print('开始运行\n')
    time.sleep(1) # 此处如果不睡的话会报错,因为主进程结束而子线程没结束
    print('运行结束')

if __name__=='__main__':
    test()
```


2. 创建 `threading.Thread` 的子类来包装一个线程对象，如下例：

```python
import threading
import time

class timer(threading.Thread): #The timer class is derived from the class threading.Thread
    def __init__(self, num, interval):
        threading.Thread.__init__(self)
        self.thread_num = num
        self.interval = interval
        self.thread_stop = False

    def run(self): #Overwrite run() method, put what you want the thread do here
        while not self.thread_stop:
            print('Thread Object(%d), Time:%s\n' %(self.thread_num, time.time()))
            time.sleep(self.interval)

    def stop(self):
        self.thread_stop = True


def test():
    thread1 = timer(1, 1)
    thread2 = timer(2, 2)
    thread1.start()
    thread2.start()
    time.sleep(10)
    thread1.stop()
    thread2.stop()
    return

if __name__ == '__main__':
    test()
```

threading.Thread类的使用：
- 在自己的线程类的 `__init__` 里调用 `threading.Thread.__init__(self, name=thread_name)` # thread_name 为线程的名字
- run()，通常需要重写，编写代码实现做需要的功能。
- getName()，获得线程对象名称
- setName()，设置线程对象名称
- start()，启动线程
- jion(timeout=None)，等待另一线程结束后再运行。如果给出timeout，则最多阻塞timeout秒
- setDaemon(bool)，设置子线程是否随主线程一起结束，必须在start()之前调用。默认为 False 。
- isDaemon()，判断线程是否随主线程一起结束。
- isAlive()，检查线程是否在运行中。
   此外threading模块本身也提供了很多方法和其他的类，可以帮助我们更好的使用和管理线程。


3. 使用 threading.Thread 启动线程对象，如下例：
```python
import threading

def worker(a_tid,a_account):
    print(a_tid,a_account)

# 参数 target 是要执行的函数, args 里面的是参数列表,kwargs是字典式的参数列表
th = threading.Thread(target=worker, args=(), kwargs={'a_tid':'a', 'a_account':2})

# 启动这个线程
th.start()

# 等待线程返回
th.join()
# 或者 threading.Thread.join(th)


# 创建锁
g_mutex = threading.Lock()
# .... code ...

# 使用锁
# 锁定，从下一句代码到释放前互斥访问
g_mutex.acquire()
# .... code ...
# 释放锁
g_mutex.release()
```


http://www.cnblogs.com/tqsummer/archive/2011/01/25/1944771.html
http://blog.sina.com.cn/s/blog_4b5039210100esc1.html
http://sm4llb0y.blog.163.com/blog/static/18912397200981594357140/


子线程随主线程一起结束
```python
import time
import threading

def test():
    while True:
        print(threading.currentThread())
        time.sleep(1)

if __name__ == '__main__':
    t1 = threading.Thread(target=test)
    # t1.setDaemon(True)
    t1.start()

    t2 = threading.Thread(target=test)
    # t2.setDaemon(True)
    t2.start()
```

    # 上面代码在 py2 下运行，使用 Ctrol + C 无法终止进程。
    # 必须设置成“守护线程”，加上 “t1.setDaemon(True)” 才可以在主线程终止时，子线程也终止。
    # py3 下好像默认就是守护线程。


多进程 (从 2.6 起增加了子进程级别的并行开发支持 —— multiprocessing)
```python
#!/usr/bin/env python
# -*- coding:utf-8 -*-

import os, time
from multiprocessing import current_process, Pool

def test(x):
    print(current_process().pid, x)
    #time.sleep(1)

if __name__ == "__main__":
    print("main:", os.getpid())
    p = Pool(5)
    p.map(test, range(13)) # 启动13个子进程
    time.sleep(1)
```

1. Process
  我们先从最根本的 Process 入手，看看是如何启动子进程完成并行计算的。上面的 Pool 不过是创建多个 Process，然后将数据(args)提交给多个子进程完成而已。

```python
import os, time
from multiprocessing import current_process, Process

def test(x):
    print(current_process().pid, x)
    time.sleep(1)

if __name__ == "__main__":
    print("main:", os.getpid())
    p = Process(target = test, args = [100])
    p.start()
    p.join()
```

程序退出时执行
```python
# 注册 atexit 函数来解决
# 如果中途关闭运行窗口，无法调用结束事件
import threading
import time
import atexit

def clean():
    print("clean temp data...")

def test():
    for i in range(10):
        name = threading.currentThread().name
        print(name, i)
        # time.sleep(1)

if __name__ == "__main__":
    atexit.register(clean) # 注册程序结束时执行的函数
    threading.Thread(target = test).start()
    time.sleep(1)

    exit(4) # quit() 和 exit() 会等待所有前台线程退出，同时会调用退出函数。
    import sys; sys.exit(4) # 和 exit / quit 作用基本相同。等待前台线程退出，调用退出函数。
    import os; os._exit(4) # os._exit() 通过系统调用来终止进程的，所有线程和退出函数统统滚蛋。

    time.sleep(1)
    print("Ho ...")

import subprocess
```

程序退出时执行
```python
# 通过 subprocess.Popen 函数来解决；但会发生问题，不知道内部是什么原因
import subprocess
proc = subprocess.Popen("python test.py")
proc.wait()

# 前面的程序结束后，才继续执行下面的代码
test_file = open('test.txt', 'wb')
test_file.write('hello') # 这里的写入偶尔会出问题，不知道原因
test_file.close()
```

控制最大线程数(范例)

```python
"""范例 1, 限制最大线程数量"""
import threading
NOTIFY_THREADS = 20  # 最大线程数
urls = get_notify_urls()  # 获取要处理的 url 列表(假设这里会返回 tuple|list 类型的数据)
# 采用多线程发请求,可大大提高效率。
threads = []
# 下面用循环控制最大线程数,且保证将 参数 urls 平均分配到各线程,每个线程处理的参数数量大致一样(误差 1 个)
for index in range(NOTIFY_THREADS):
    th = threading.Thread(target=send_urls,
                          args=(urls[index::NOTIFY_THREADS],))  # 处理数据的函数名为 send_urls, 接收参数: {list} urls
    th.start()  # 启动这个线程
    threads.append(th)
# 等待各线程返回,避免定时器下次再来重复调用,也为了控制线程数量
for th in threads:
    th.join()
```

```python
"""范例 2, 限制最大线程数量,且根据 uid 分配线程(同一个 uid 须保证在同一个线程内)"""
import threading
SEND_PRODUCT_THREAD = 20  # 最大线程数
products = query_products(500)  # 获取产品列表(假设这里会返回 tuple<dict> 类型的数据,其中 dict 里面包含 uid 字段)
if not products:
    return
# 使用多线程,但需要保证顺序,同一个uid的发货需要保证在同一个线程中
thread_products = {}  # 先用一个 dict 来保存各线程需要处理的数据列表,然后逐个遍历这个 dict 来启动多线程
for product_data in products:
    uid = product_data['uid']
    mo = str(uid % SEND_PRODUCT_THREAD)  # 对uid取模
    product_list = thread_products.get(mo)
    if not product_list:
        product_list = []
        thread_products[mo] = product_list
    product_list.append(product_data)
# 发启各线程处理数据
thread_list = []
for mo, product_list in thread_products.items():
    # 处理数据的函数名为 send_product, 接收参数: {list<{dict} product_data>} product_list
    th = threading.Thread(target=send_product, args=(product_list,))
    th.start()  # 启动这个线程
    thread_list.append(th)  # 保存这个线程
# 等待各线程返回
for th in thread_list:
    th.join()
```

```python
"""范例 3, 限制最大线程数量，线程处理完一个任务后，自动接下一个任务"""
import re
import os
import sys
import time
import logging
import threading
PY2 = sys.version_info[0] == 2
if PY2:
    from Queue import Queue
else:
    from queue import Queue
THREAD_LINE = int(os.getenv('THREAD_LINE', 5))  # 线程数

def get_list(html, sub_title):
    """获取各个子文章"""
    start_time = time.time()
    url_queue = Queue()  # 需处理的数据，放进队列
    # 这里假设，队列里需要处理的数据量，远大于线程数
    result = re.findall(r'<a href="(/view/.+?\.html)" title="([^"<>]+?)" target="_blank">', html, re.I)
    for (child_path, title) in result:
        if THREAD_LINE > 1:  # 开启多线程处理
            url_queue.put((child_path, title, sub_title))
        else:  # 单线程处理
            get_child(child_path, title, sub_title)

    if THREAD_LINE > 1:
        tl = []
        # 每次线程都等待所有的一起结束,避免主程序结束而线程未结束导致发不成功
        for i in range(THREAD_LINE):
            th = threading.Thread(target=queue_child, args=(url_queue,))
            tl.append(th)
            th.start()  # 启动这个线程
            time.sleep(0.05)  # 避免抓取太频繁，导致ip被封
        for th in tl:
            th.join()  # 等待线程返回
    logging.info(f'获取各个子文章，共{len(result)}个子文章，耗时: {time.time() - start_time} 秒\r\n')

def queue_child(url_queue):
    while not url_queue.empty():
        child_path, title, sub_title = url_queue.get_nowait()
        get_child(child_path, title, sub_title)
        url_queue.task_done()

def get_child(child_path, title, sub_title):
    """获取子文章(代理略)"""
```


线程锁(线程安全)
```python
import time
import threading

# 线程安全锁
mylock = threading.RLock()
num = 1

def http():
    global num
    mylock.acquire() # 开启线程安全锁
    num += 1
    print(num)
    time.sleep(0.1)
    print(time.time())
    mylock.release() # 释放锁

threading_list = []
for i in range(10):
    th = threading.Thread(target = http)
    th.start()
    threading_list.append(th)

for th in threading_list:
    th.join()
```

线程定时器  
    调用threading提供的定时器。定时器在指定时间之后开始执行，在执行前还可以取消执行。
```python
import threading
import time

def delayed():
    print('worker running')
    return

t1 = threading.Timer(3, delayed) # 指定 3 秒后运行 delayed 函数
t1.setName('t1')

print(time.localtime())
print('starting timers')
t1.start()

time.sleep(2)
print(time.localtime())
#t1.cancel() # 在执行前可以取消执行
print('done')
# 会在打印 done 之后执行 delayed 函数,打印 'worker running'
```

# 协程
协程（Coroutine，又称微线程，纤程）是一种比线程更加轻量级的存在，协程不是被操作系统内核所管理，而完全是由程序所控制。  
如同一个进程可以有很多线程一样，一个线程可以有很多协程。  
但是，协程不是被操作系统所管理的，没有改变CPU最小执行单元是线程，协程是完全由程序所控制的（用户态执行），不会产生上下文切换。  
协程具有高并发、高扩展性、低成本的特点，一个CPU支持上万的协程都不是问题。所以，很适合用于高并发处理。  
通常，协程可以处理IO密集型程序的效率问题，但是处理CPU密集型不是它的长处，如要充分发挥CPU利用率可以结合多进程+协程。  

### 优点
- 无需线程上下文切换的开销
- 无需原子操作锁定及同步的开销
- 方便切换控制流，简化编程模型

### 缺点
无法利用多核资源：协程的本质是个单线程，它不能同时在多个核用上。  
协程需要和进程配合才能运行在多CPU上。  
当然我们日常所编写的绝大部分应用都没有这个必要，除非是cpu密集型应用。  
进行阻塞（Blocking）操作（如IO时）会阻塞掉整个程序。



# 多进程、多线程、协程 的区别
- 多进程：每个进程有独立的内存空间，资源占用较多，但相对独立，不存在线程安全问题。
- 多线程：线程之间共享进程的内存空间，资源占用较少，但需要注意线程安全问题。 
- 协程：在同一个线程内执行，共享线程的内存空间，资源占用较少，但需要避免阻塞操作。

## 并行比较
- 多进程：多个进程在多核CPU上可以实现真正的并行执行，适用于CPU密集型任务。
- 多线程：由于全局解释器锁(GIL)的存在，多线程在Python中无法实现真正的并行执行。
- 协程：在同一个线程内切换执行任务，不涉及多核CPU的并行执行，适用于高并发的I/O密集型任务。

## 编程模型比较
- 多进程：通常使用进程对象和队列来实现进程间的数据传递和同步。
- 多线程：通常使用线程对象和锁来实现线程间的同步与通信。
- 协程：使用异步/等待关键字和事件循环来定义和管理协程。

## GIL
- 首先需要明确的一点是GIL并不是Python的特性，它是在实现Python解析器(CPython)时所引入的一个概念。
- 同样一段代码可以通过CPython，PyPy，Psyco等不同的Python执行环境来执行。像其中的JPython就没有GIL。
- 然而因为CPython是大部分环境下默认的Python执行环境。所以在很多人的概念里CPython就是Python，也就想当然的把GIL归结为Python语言的缺陷。
- 所以这里要先明确一点：GIL并不是Python的特性，Python完全可以不依赖于GIL。
- 
- Python为了解决多线程之间数据完整性和状态同步的最简单方法自然就是加锁。
- 于是有了GIL这把超级大锁，而当越来越多的代码库开发者接受了这种设定后，他们开始大量依赖这种特性（即默认python内部对象是thread-safe的，无需在实现时考虑额外的内存锁和同步操作）。
- 慢慢的这种实现方式被发现是蛋疼且低效的。但当大家试图去拆分和去除GIL的时候，发现大量库代码开发者已经重度依赖GIL而非常难以去除了。
- 所以简单的说GIL的存在更多的是历史原因。如果推到重来，多线程的问题依然还是要面对，但是至少会比目前GIL这种方式会更优雅。
- 
- Python社区也在非常努力的不断改进GIL，甚至是尝试去除GIL。并在各个小版本中有了不少的进步。
- GIL其实是功能和性能之间权衡后的产物，它有其存在的合理性，也有较难改变的客观因素。我们可以做以下一些简单的总结：
- 因为GIL的存在，只有IO密集型场景下得多线程会得到较好的性能
- 如果对并行计算性能较高的程序可以考虑把核心部分改成C模块，或者索性用其他语言实现
- GIL在较长一段时间内将会继续存在，但是会不断对其进行改进


