
# Python的Sync与Async执行速度的快慢

## 前记
Python3 的版本中支持了 `async/await` 语法， 很多文章都在说这种语法的实现代码会变得很快， 但是这种快是有场景限制的。
这篇文章将尝试简单的解释为何`Async`的代码在某些场景比`Sync`的代码快。

## CPU运行差异
- 首先先从一个例子了解两种调用方法的差别, 为了能清晰的看出他们的运行时长差别， 都让他们重复运行10000次， 具体代码如下：

```python3
import asyncio
import time

n_call = 10000

# sync的调用时长
def demo(n: int) -> int:
    return n ** n

s_time = time.time()
for i in range(n_call):
    demo(i)
print(time.time() - s_time)

# async的调用时长
async def sub_demo(n: int) -> int:
    return n ** n

async def async_main() -> None: 
    for i in range(n_call):
        await sub_demo(i)

loop = asyncio.get_event_loop()
s_time = time.time()
loop.run_until_complete(async_main())
print(time.time() - s_time)

# 输出
# 5.310615682601929
# 5.614157438278198
```


可以看得出来， `sync`的语法大家都是很熟悉， 而`async`的语法比较不一样， 函数需要使用`async def`开头， 同时调用`async def`函数需要使用`await`语法， 
运行的时候需要先获取线程的事件循环， 然后在通过事件循环来运行`async_main`函数来达到一样的效果， 
但是从运行结果的输出可以看得出, `sync`的语法在这个场景中比`async`的语法速度快了一丢丢（由于Python的GIL原因， 这里无法使用多核的性能， 只能以单核来跑）。

造成这样的原因是同样由同一个线程执行的情况下(cpu单核心)，`async`的调用还需要经过一些事件循环的额外调用， 
这会产生一些小开销， 从而运行时间会比`sync`的慢， 同时这是一个纯cpu运算的示例， 
而`async`的的优势在于网络io运算， 在这个场景无法发挥优势， 但会在高并发场景则会大放光彩, 造成这样的原因则是因为`async`是以协程运行的， `sync`是以线程运行的。


# 协程的实现

## 传统的 Sync 语法请求例子
- `Async`语法的实现之前， 先从一个`Sync`的语法例子开始， 
- 现在假设有一个HTTP请求， 这个程序会通过这个请求获取对应的响应内容， 并打印出来, 代码如下：

```python3
import socket

def request(host: str) -> None:
    """模拟请求并打印响应体"""
    url: str = f"http://{host}"
    sock: socket.SocketType = socket.socket()
    sock.connect((host, 80))
    sock.send(f"GET {url} HTTP/1.0\r\nHost: {host}\r\n\r\n".encode("ascii"))

    response_bytes: bytes = b""
    chunk: bytes = sock.recv(4096)
    while chunk:
        response_bytes += chunk
        chunk = sock.recv(4096)
    print("\n".join([i for i in response_bytes.decode().split("\r\n")]))

if __name__ == "__main__":
    request("so1n.me")
```

运行程序， 程序能够正常输出, 上部分打印了对应的HTTP响应Header, 下部分打印了HTTP响应体, 可以看到服务端叫我们以https的形式重新请求， 输出结果如下：
```text
HTTP/1.1 301 Moved Permanently
Server: GitHub.com
Content-Type: text/html
Location: https://so1n.me/
X-GitHub-Request-Id: A744:3871:4136AF:48BD9F:6188DB50
Content-Length: 162
Accept-Ranges: bytes
Date: Mon, 08 Nov 2021 08:11:37 GMT
Via: 1.1 varnish
Age: 104
Connection: close
X-Served-By: cache-qpg1272-QPG
X-Cache: HIT
X-Cache-Hits: 2
X-Timer: S1636359097.026094,VS0,VE0
Vary: Accept-Encoding
X-Fastly-Request-ID: 22fa337f777553d33503cee5282598c6a293fb5e

<html>
<head><title>301 Moved Permanently</title></head>
<body>
<center><h1>301 Moved Permanently</h1></center>
<hr><center>nginx</center>
</body>
</html>
```
在这个代码中， `socket`的默认调用是阻塞的， 当线程调用`connect`或者`recv`时
(`send`是不用等待的， 但在高并发下需要先等待`drain`后才可以`send`, 小demo不需要用到drain方法)， 程序将会暂停直到操作完成。 

当一次要下载很多网页的话， 这将会如上篇文章所说的一样， 大部分的等待时间都花在io上面， cpu却一直空闲时， 
而使用线程池虽然可以解决这个问题， 但是开销是很大的， 同时操作系统往往会限制一个进程，用户或者机器可以使用的线程数， 而协程却没有这些限制， 占用的资源少， 也没有系统限制瓶颈。


## 异步的请求
异步可以让一个单独的线程处理并发的操作， 不过在上面已经说过了， `socket`是默认阻塞的， 所以需要把`socket`设置为非阻塞的,  
`socket`提供了`setblocking`这个方法供开发者选择是否阻塞， 在设置了非阻塞后， `connect`和`recv`方法也要进行更改。

由于没有了阻塞， 程序在调用了`connect`后会马上返回， 只不过Python的底层是C, 这段代码在C中调用非阻塞的`socket.connect`后会抛出一个异常， 我们需要捕获它， 就像这样：
```python3
import socket

sock: socket.SocketType = socket.socket()
sock.setblocking(Flase)
try:
    sock.connect(("so1n.me", 80))
except BlockingIOError:
    pass
```

经过一顿操作后， 就开始申请建立连接了， 但是我们还不知道连接啥时候完成建立， 
由于连接没建立时调用`send`会报错， 所以可以一直轮询调用`send`直到没报错就认为是成功（真实代码需要加超时）：
```python3
while True:
    try: 
        sock.send(request)
        break
    except OSError as e:
        pass
```

但是这样让CPU空转太浪费性能了， 而且期间还不能做别的事情， 
就像我们点外卖后一直打电话过去问饭菜做好了没有， 十分浪费电话费用， 要是饭菜做完了就打电话告诉我们， 那就只产生了一笔费用， 非常的省钱（正常情况下也是这样子）。

这时就需要事件循环登场了，在类UNIX中， 有一个叫`select`的功能， 它可以等待事件发生后再调用监听的函数， 不过一开始的实现性能不是很好， 在Linux上被`epoll`取代， 
不过接口是类似的， 所在在Python中把这几个不同的事件循环都封装在`selectors`库中， 同时可以通过`DefaultSelector`从系统中挑出最好的类`select`函数。
这里先暂时不说事件循环的原理， 事件循环最主要的是他名字的两部分， 一个是事件， 一个是循环， 在Python中， 可以通过如下方法把事件注册到事件循环中：
```python3
def demo(): pass

selector.register(fd, EVENT_WRITE, demo)
```

这样这个事件循环就会监听对应的文件描述符fd, 当这个文件描述符触发写入事件(EVENT_WRITE)时，事件循环就会告诉我们可以去调用注册的函数`demo`。
不过如果把上面的代码都改为这种方法去运行的话就会发现， 程序好像没跑就结束了， 
但程序其实是有跑的， 只不过他们是完成的了注册， 然后就等待开发者接收事件循环的事件进行下一步的操作， 所以我们只需要在代码的最后面写上如下代码:
```python3
while True:
    for key, mask in selector.select():
        key.data()
```

这样程序就会一直运行, 当捕获到事件的时候， 就会通过`for`循环告诉我们， 其中`key.data`是我们注册的回调函数， 当事件发生时， 就会通知我们， 
我们可以通过拿到回调函数然后就运行, 了解完毕后， 我们可以来编写我们的第一个并发程序， 他实现了一个简单的I/O复用的小逻辑, 代码和注释如下：

```python3
import socket
from selectors import DefaultSelector, EVENT_READ, EVENT_WRITE


# 选择事件循环
selector: DefaultSelector = DefaultSelector()
# 用于判断是否有事件在运行
running_cnt: int = 0


def request(host: str) -> None:
    """模拟请求并打印响应体"""
    # 告诉主函数， 自己的事件还在运行
    global running_cnt
    running_cnt += 1

    # 初始化socket
    url: str = f"http://{host}"
    sock: socket.SocketType = socket.socket()
    sock.setblocking(False)
    try:
        sock.connect((host, 80))
    except BlockingIOError:
        pass

    response_bytes: bytes = b""
    file_no: int = sock.fileno()

    def read_response() -> None:
        """接收响应参数， 并判断请求是否结束"""
        nonlocal response_bytes
        chunk: bytes = sock.recv(4096)
        print(f"{file_no} recv {host} body success")
        if chunk:
            response_bytes += chunk
        else:
            # 没有数据代表请求结束了， 注销监听
            selector.unregister(file_no)
            global running_cnt
            running_cnt -= 1
            print(f"{file_no} recv {host} body: {response_bytes}")

    def connected() -> None:
        """socket建立连接时的回调"""
        # 取消监听
        selector.unregister(sock.fileno())
        print(f"{file_no} {host} connect success")
        # 发送请求， 并监听读事件， 以及注册对应的接收响应函数
        sock.send(f"GET {url} HTTP/1.0\r\nHost: {host}\r\n\r\n".encode("ascii"))
        selector.register(file_no, EVENT_READ, read_response)

    selector.register(file_no, EVENT_WRITE, connected)


if __name__ == "__main__":
    # 同时多个请求
    request("so1n.me")
    request("163.com")
    request("baidu.com")
    # 监听是否有事件在运行
    while running_cnt > 0:
        # 等待事件循环通知事件是否已经完成
        for key, mask in selector.select():
            key.data()
```
这段代码接近同时注册了3个请求并注册建立连接回调， 然后就进入事件循环逻辑， 也就是把控制权交给事件循环， 
直到事件循环告诉程序说收到了`socket`建立的通知， 程序就会取消注册的回调然后发送请求， 并注册一个读的事件回调， 然后又把控制权交给事件循环， 直到收到了响应的结果才进入处理响应结果函数并且只有收完所有响应结果才会退出程序。 下面是我其中的一次执行结果

打印结果如：
```text
7 163.com connect success
8 baidu.com connect success
7 recv 163.com body success
7 recv 163.com body success
7 recv 163.com body: b'HTTP/1.1 301 Moved Permanently\r\nServer: nginx\r\nDate: Tue, 17 May 。。。'
8 recv baidu.com body success
8 recv baidu.com body success
8 recv baidu.com body: b'HTTP/1.1 200 OK\r\nDate: Tue, 17 May 2022 09:45:24 GMT\r\nServer: 。。。'
4 so1n.me connect success
4 recv so1n.me body success
4 recv so1n.me body success
4 recv so1n.me body: b'HTTP/1.1 301 Moved Permanently\r\nServer: GitHub.com\r\nContent-Ty。。。'
```

可以看到他们的执行顺序是随机的， 同时他们执行速度很快， 这个程序的耗时约等于响应时长最长的函数耗时。
但是可以看出， 这个程序里面出现了两个回调， 回调会让代码变得非常的奇怪, 降低可读性， 也容易造成回调地狱， 
而且当回调发生报错的时候， 我们是很难知道这是由于什么导致的错误， 因为它的上下文丢失了， 这样子排查问题十分的困惑。 
作为程序员， 一般都不止满足于速度快的代码， 真正想要的是又快， 又能像`Sync`的代码一样简单, 可读性强, 也能容易排查问题的代码, 这种组合形式的代码的设计模式就叫协程。

协程出现得很早， 它不像线程一样， 被系统调度， 而是能自主的暂停， 并等待事件循环通知恢复。
由于协程是软件层面实现的， 所以它的实现方式有很多种， 这里要说的是基于生成器的协程， 
因为生成器跟协程一样， 都有暂停让步和恢复的方法(还可以通过throw来抛错）， 同时它跟Async语法的协程很像， 通过了解基于生成器的协程， 可以了解Async的协程是如何实现的。


## 基于生成器的协程

### 生成器
Python的生成器函数与普通的函数会有一些不同, 只要普通函数中带有关键字`yield`， 那么它就是生成器函数， 具体有什么不同可以通过他们的字节码来了解：
```python3
import dis

# 普通函数
def aaa(): return 1111

print(dis.dis(aaa))
print('*'*30)


# 普通函数调用函数
def bbb():
    aaa()
    return 2222

print(dis.dis(bbb))
print('*'*30)


# 普通生成器函数
def ccc(): yield 3333

print(dis.dis(ccc))
print('*'*30)
```

打印结果如：
```text
 11           0 LOAD_CONST               1 (1111)
              2 RETURN_VALUE
None
******************************
 19           0 LOAD_GLOBAL              0 (aaa)
              2 CALL_FUNCTION            0
              4 POP_TOP

 20           6 LOAD_CONST               1 (2222)
              8 RETURN_VALUE
None
******************************
 27           0 LOAD_CONST               1 (3333)
              2 YIELD_VALUE
              4 POP_TOP
              6 LOAD_CONST               0 (None)
              8 RETURN_VALUE
None
******************************
```
上面分别是普通函数， 普通函数调用函数和普通生成器函数的字节码， 从字节码可以看出来， 
最简单的函数只需要`LOAD_CONST`来加载变量`1111`压入自己的栈， 然后通过`RETURN_VALUE`来返回值， 
而有函数调用的普通函数则先加载变量， 把全局变量的函数`aaa`加载到自己的栈里面， 然后通过`CALL_FUNCTION`来调用函数， 最后通过`POP_TOP`把函数的返回值从栈里抛出来， 再把通过`LOAD_CONST`把`2222`压入自己的栈， 最后返回值。
而生成器函数则不一样， 它会先通过`LOAD_CONST`来加载变量`3333`压入自己的栈， 然后通过`YIELD_VALUE`返回值， 接着通过`POP_TOP`弹出刚才的栈并重新把变量`None`压入自己的栈， 最后通过`RETURN_VALU`E来返回值。

从字节码来分析可以很清楚的看到， 生成器能够在`yield`区分两个栈帧, 一个函数调用可以分为多次返回， 很符合协程多次等待的特点。

接着来看看生成器的一个使用, 这个生成器会有两次`yield`调用, 并在最后返回字符串`None`， 代码如下：

```python3
def demo():
    a = 1
    b = 2
    print('aaa', locals())
    yield 1
    print('bbb', locals())
    yield 2
    return 'None'

demo_gen = demo()
print('*'*30)
print('resule1', demo_gen.send(None))
print('*'*30)
print('resule2', demo_gen.send(None))
print('*'*30)
print('resule3', demo_gen.send(None))
print('*'*30)
```

打印结果如：
```text
******************************
aaa {'a': 1, 'b': 2}
resule1 1
******************************
bbb {'a': 1, 'b': 2}
resule2 2
******************************
Traceback (most recent call last):
  File "_test1.py", line 16, in <module>
    print('resule1', demo_gen.send(None))
StopIteration: None
```

这段代码首先通过函数调用生成一个`demo_gen`的生成器对象, 然后第一次`send`调用时返回值`1`， 第二次`send`调用时返回值`2`，
第三次`send`调用则抛出`StopIteration`异常， 异常提示为`None`, 
同时可以看到第一次打印`aaa`和第二次打印`bbb`时， 他们都能打印到当前的函数局部变量， 
可以发现在即使在不同的栈帧中， 他们读取到当前的局部函数内的局部变量是一致的， 这意味着如果使用生成器来模拟协程时， 它还是会一直读取到当前上下文的， 非常的完美。

此外， Python还支持通过`yield from`语法来返回一个生成器, 代码如下:
```python3
def demo_gen_1():
    for i in range(3):
        yield i

def demo_gen_2(): 
    yield from demo_gen_1()

demo_gen_obj = demo_gen_2()
for i in range(4):
    print('resule', i, demo_gen_obj.send(None))
```
打印结果如：
```text
resule 0 0
resule 1 1
resule 2 2
Traceback (most recent call last):
  File "_test1.py", line 11, in <module>
    print('resule', i, demo_gen_obj.send(None))
StopIteration
```

通过`yield from`就可以很方便的支持生成器调用， 假如把每个生成器函数都当做一个协程， 那通过`yield from`就可以很方便的实现协程间的调用， 
此外生成器的抛出异常后的提醒非常人性化， 也支持`throw`来抛出异常， 这样我们就可以实现在协程运行时设置异常， 比如`Cancel`，演示代码如下:

```python3
def demo_exc():
    yield 1
    raise RuntimeError()

demo_exc_gen = demo_exc()
print('resule', demo_exc_gen.send(None))
print('resule', demo_exc_gen.send(None))  # 运行这行会抛出异常 RuntimeError
```

```python3
def demo_exc_1():
    for i in range(3):
        yield i

demo_exc_gen_1 = demo_exc_1()
print('resule', demo_exc_gen_1.send(None))
print('resule', demo_exc_gen_1.send(None))
demo_exc_gen_1.throw(RuntimeError)  # 主动抛出异常 RuntimeError
```
从中可以看到在运行中抛出异常时， 会有一个非常清楚的抛错， 可以明显看出错误堆栈， 
同时`throw`指定异常后， 会在下一处`yield`抛出异常(所以协程调用`Cancel`后不会马上取消， 而是下一次调用的时候才被取消)。


### 用生成器实现协程
我们已经简单的了解到了生成器是非常的贴合协程的编程模型， 同时也知道哪些生成器API是我们需要的API， 接下来可以模仿Asyncio的接口来实现一个简单的协程。

首先是在`Asyncio`中有一个封装叫`Feature`, 它用来表示协程正在等待将来时的结果, 
以下是我根据`asyncio.Feature`封装的一个简单的`Feature`, 它的API没有`asyncio.Feature`全, 代码和注释如下:

```python3
import asyncio
from typing import Any, Optional, List, Callable
DEBUG = True

class Status:
    """用于判断Future状态"""
    pending: int = 1
    finished: int = 2
    cancelled: int = 3

# from asyncio import Future  # 下面自己写一个 Future
class Future(object):

    def __init__(self) -> None:
        """初始化时， Feature处理pending状态， 等待set result"""
        if DEBUG: print('start Future.__init__')
        self.status: int = Status.pending
        self._result: Any = None
        self._exception: Optional[Exception] = None
        self._callbacks: List[Callable[['Future'], None]] = []
        if DEBUG: print('end Future.__init__')

    def add_done_callback(self, fn: Callable[['Future'], None]) -> None:
        """添加完成时的回调"""
        if DEBUG: print('start Future.add_done_callback', fn)
        self._callbacks.append(fn)
        if DEBUG: print('end Future.add_done_callback')

    def cancel(self):
        """取消当前的Feature"""
        if DEBUG: print('start Future.cancel')
        if self.status != Status.pending:
            return False
        self.status = Status.cancelled
        for fn in self._callbacks:
            fn(self)
        if DEBUG: print('end Future.cancel')
        return True

    def set_exception(self, exc: Exception) -> None:
        """设置异常"""
        if DEBUG: print('start Future.set_exception', exc)
        if self.status != Status.pending:
            raise RuntimeError("Can not set exc")
        self._exception = exc
        self.status = Status.finished
        if DEBUG: print('end Future.set_exception')

    def set_result(self, result: Any) -> None:
        """设置结果"""
        if DEBUG: print('start Future.set_result', result)
        if self.status != Status.pending:
            raise RuntimeError("Can not set result")
        self.status = Status.finished
        self._result = result
        for fn in self._callbacks:
            fn(self)
        if DEBUG: print('end Future.set_result')

    def result(self):
        """获取结果"""
        if DEBUG: print('start Future.result')
        if self.status == Status.cancelled:
            raise asyncio.CancelledError
        elif self.status != Status.finished:
            raise RuntimeError("Result is not read")
        elif self._exception is not None:
            raise self._exception
        if DEBUG: print('end Future.result')
        return self._result

    def __iter__(self):
        """通过生成器来模拟协程， 当收到结果通知时， 会返回结果"""
        if DEBUG: print('start Future.__iter__')
        if self.status == Status.pending:
            yield self
        if DEBUG: print('end Future.__iter__')
        return self.result()
```


在理解`Future`时， 可以把它假想为一个状态机， 在启动初始化的时候是`peding`状态， 在运行的时候我们可以切换它的状态, 
并且通过`__iter__`方法来支持调用者使用`yield from Future()`来等待`Future`本身， 直到收到了事件通知时， 可以得到结果。

但是可以发现这个`Future`是无法自我驱动, 调用了`__iter__`的程序不知道何时被调用了`set_result`， 
在`Asyncio`中是通过一个叫`Task`的类来驱动`Future`, 它将一个协程的执行过程安排好， 并负责在事件循环中执行该协程。它主要有两个方法:

1.初始化时， 会先通过`send`方法激活生成器
2.后续被调度后马上安排下一次等待， 除非抛出`StopIteration`异常

还有一个支持取消运行托管协程的方法(在原代码中， `Task`是继承于`Future`, 所以`Future`有的它都有), 经过简化后的代码如下：

```python3
import asyncio
# from asyncio import Future  # 从上面文件导入 Future
from typing import Generator
DEBUG = True

class Task:
    def __init__(self, coro: Generator) -> None:
        if DEBUG: print('start Task.__init__', coro)
        # 初始化状态
        self.cancelled: bool = False
        self.coro: Generator = coro
        # 预激一个普通的future
        f: Future = Future()
        f.set_result(None)
        self.step(f)
        if DEBUG: print('end Task.__init__')

    def cancel(self) -> None:
        """用于取消托管的coro"""
        if DEBUG: print('start Task.cancel')
        self.coro.throw(asyncio.CancelledError)
        if DEBUG: print('end Task.cancel')

    def step(self, f: Future) -> None:
        """用于调用coro的下一步, 从第一次激活开始， 每次都添加完成时的回调， 直到遇到取消或者StopIteration异常"""
        if DEBUG: print('start Task.step', f)
        try:
            _future = self.coro.send(f.result())
        except asyncio.CancelledError:
            self.cancelled = True
            return
        except StopIteration:
            return
        finally:
            if DEBUG: print('end Task.step.except')

        _future.add_done_callback(self.step)
        if DEBUG: print('end Task.step')
```


这样`Future`和`Task`就封装好了， 可以简单的试一试效果如何:
```python3
def wait_future(f: Future, flag_int: int) -> Generator[Future, None, None]:
    result = yield from f
    print(flag_int, result)

future: Future = Future()
for i in range(3):
    coro = wait_future(future, i)
    # 托管wait_future这个协程， 里面的Future也会通过yield from被托管
    Task(coro)

print('--- ready ---')
future.set_result('ok')

print('--- cancel ---')
future = Future()
Task(wait_future(future, 3)).cancel()
```

输出结果:
```text
start Future.__init__
end Future.__init__
start Task.__init__ <generator object wait_future at 0x7fcc001e29d0>
start Future.__init__
end Future.__init__
start Future.set_result None
end Future.set_result
start Task.step <__main__.Future object at 0x7fcc002212d0>
start Future.result
end Future.result
start Future.__iter__
end Task.step.except
start Future.add_done_callback <bound method Task.step of <__main__.Task object at 0x7fcc00221290>>
end Future.add_done_callback
end Task.step
end Task.__init__
start Task.__init__ <generator object wait_future at 0x7fcc001e2bd0>
start Future.__init__
end Future.__init__
start Future.set_result None
end Future.set_result
start Task.step <__main__.Future object at 0x7fcc00221310>
start Future.result
end Future.result
start Future.__iter__
end Task.step.except
start Future.add_done_callback <bound method Task.step of <__main__.Task object at 0x7fcc002212d0>>
end Future.add_done_callback
end Task.step
end Task.__init__
start Task.__init__ <generator object wait_future at 0x7fcc001e2cd0>
start Future.__init__
end Future.__init__
start Future.set_result None
end Future.set_result
start Task.step <__main__.Future object at 0x7fcc00221350>
start Future.result
end Future.result
start Future.__iter__
end Task.step.except
start Future.add_done_callback <bound method Task.step of <__main__.Task object at 0x7fcc00221310>>
end Future.add_done_callback
end Task.step
end Task.__init__
--- ready ---
start Future.set_result ok
start Task.step <__main__.Future object at 0x7fcc00221250>
start Future.result
end Future.result
end Future.__iter__
start Future.result
end Future.result
0 ok
end Task.step.except
start Task.step <__main__.Future object at 0x7fcc00221250>
start Future.result
end Future.result
end Future.__iter__
start Future.result
end Future.result
1 ok
end Task.step.except
start Task.step <__main__.Future object at 0x7fcc00221250>
start Future.result
end Future.result
end Future.__iter__
start Future.result
end Future.result
2 ok
end Task.step.except
end Future.set_result
--- cancel ---
start Future.__init__
end Future.__init__
start Task.__init__ <generator object wait_future at 0x7fcc001e29d0>
start Future.__init__
end Future.__init__
start Future.set_result None
end Future.set_result
start Task.step <__main__.Future object at 0x7fcc00221290>
start Future.result
end Future.result
start Future.__iter__
end Task.step.except
start Future.add_done_callback <bound method Task.step of <__main__.Task object at 0x7fcc00221250>>
end Future.add_done_callback
end Task.step
end Task.__init__
start Task.cancel
Traceback (most recent call last):
  File "_test1.py", line 133, in <module>
    Task(wait_future(future, 3)).cancel()
  File "_test1.py", line 97, in cancel
    self.coro.throw(asyncio.CancelledError)
  File "_test1.py", line 118, in wait_future
    result = yield from f
  File "_test1.py", line 77, in __iter__
    yield self
concurrent.futures._base.CancelledError
```

这段程序会先初始化`Future`, 并把`Future`传给`wait_future`并生成生成器, 再交由给`Task`托管， 预激, 
由于`Future`是在生成器函数`wait_future`中通过`yield from`与函数绑定的， 真正被预激的其实是`Future`的`__iter__`方法中的`yield self`, 
此时代码逻辑会暂停在`yield self`并返回。

在全部预激后， 通过调用`Future`的`set_result`方法， 使`Future`变为结束状态， 由于`set_result`会执行注册的回调， 
这时它就会执行托管它的`Task`的`step`方法中的`send`方法, 代码逻辑回到`Future`的`__iter__`方法中的`yield self`， 并继续往下走，
然后遇到`return`返回结果, 并继续走下去, 从输出可以发现程序封装完成且打印了`ready`后， 会依次打印对应的返回结果， 
而在最后一个的测试`cancel`方法中可以看到，`Future`抛出异常了， 同时这些异常很容易看懂， 能够追随到调用的地方。

现在`Future`和`Task`正常运行了， 可以跟我们一开始执行的程序进行整合, 代码如下：

```python3
import socket
from selectors import DefaultSelector, EVENT_READ, EVENT_WRITE
# from asyncio import Future, Task  # 必须使用上面自定义的

# 选择事件循环
selector: DefaultSelector = DefaultSelector()
# 用于判断是否有事件在运行
running_cnt: int = 0

class HttpRequest(object):
    def __init__(self, host: str):
        """初始化变量和sock"""
        self._host: str = host
        global running_cnt
        running_cnt += 1
        self.url: str = f"http://{host}"
        self.sock: socket.SocketType = socket.socket()
        self.sock.setblocking(False)
        try:
            self.sock.connect((host, 80))
        except BlockingIOError:
            pass

    def read(self) -> Generator[Future, None, bytes]:
        """从socket获取响应数据， 并set到Future中， 并通过Future.__iter__方法或得到数据并通过变量chunk_future返回"""
        f: Future = Future()
        selector.register(self.sock.fileno(), EVENT_READ, lambda: f.set_result(self.sock.recv(4096)))
        chunk_future = yield from f
        selector.unregister(self.sock.fileno())
        return chunk_future  # type: ignore

    def read_response(self) -> Generator[Future, None, bytes]:
        """接收响应参数， 并判断请求是否结束"""
        response_bytes: bytes = b""
        chunk = yield from self.read()
        while chunk:
            response_bytes += chunk
            chunk = yield from self.read()
        return response_bytes

    def connected(self) -> Generator[Future, None, None]:
        """socket建立连接时的回调"""
        # 取消监听
        f: Future = Future()
        selector.register(self.sock.fileno(), EVENT_WRITE, lambda: f.set_result(None))
        yield f
        selector.unregister(self.sock.fileno())
        print(f"{self._host} connect success")

    def request(self) -> Generator[Future, None, None]:
        # 发送请求， 并监听读事件， 以及注册对应的接收响应函数
        yield from self.connected()
        self.sock.send(f"GET {self.url} HTTP/1.0\r\nHost: {self._host}\r\n\r\n".encode("ascii"))
        response = yield from self.read_response()
        print(f"request {self._host} success, length:{len(response)}")
        global running_cnt
        running_cnt -= 1

if __name__ == "__main__":
    # 同时多个请求
    Task(HttpRequest("so1n.me").request())
    Task(HttpRequest("163.com").request())
    Task(HttpRequest("baidu.com").request())
    # 监听是否有事件在运行
    while running_cnt > 0:
        # 等待事件循环通知事件是否已经完成
        for key, mask in selector.select():
            key.data()
```

这段代码通过`Future`和生成器方法尽量的解耦回调函数， 如果忽略了`HttpRequest`中的`connected`和`read`方法则可以发现整段代码跟同步的代码基本上是一样的,
只是通过`yield`和`yield from`交出控制权和通过事件循环恢复控制权。 

同时通过上面的异常例子可以发现异常排查非常的方便， 这样一来就没有了回调的各种糟糕的事情， 开发者只需要按照同步的思路进行开发即可， 
不过我们的事件循环是一个非常简单的事件循环例子， 同时对于`socket`相关都没有进行封装， 也缺失一些常用的API， 
而这些都会被Python官方封装到`Asyncio`这个库中， 通过该库， 我们可以近乎完美的编写`Async`语法的代码。

NOTE: 由于生成器协程中无法通过`yield from`语法使用生成器， 所以Python在3.5之后使用了`Await`的原生协程。
